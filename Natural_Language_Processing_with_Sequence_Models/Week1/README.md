# Recurrent Neural Networks for Language Modeling

Learn about the limitations of traditional language models and see how RNNs and GRUs use sequential data for text prediction. Then build your own next-word generator using a simple RNN on Shakespeare text data!

## Learning Objectives

- Supervised machine learning
- Binary classification
- Neural networks
- N-grams
- Gated recurrent units
- Recurrent neural networks

## Introduction to Neural Networks and TensorFlow

- [Video - Course 3 Introduction](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/rz8aj/course-3-introduction)

- [Video - Lesson Introduction](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/Sf4g4/lesson-introduction)

- [Reading - Lesson Introduction Clarification](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/qV6Eb/lesson-introduction-clarification)

- [Video - Neural Networks for Sentiment Analysis](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/E3opc/neural-networks-for-sentiment-analysis)

- [Reading - Neural Networks for Sentiment Analysis](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/cLSLo/neural-networks-for-sentiment-analysis)

- [Video - Dense Layers and ReLU](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/AGDYm/dense-layers-and-relu)

- [Reading - Dense Layers and ReLU](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/9G7vx/dense-layers-and-relu)

- [Video - Dense Layers and ReLU](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/AGDYm/dense-layers-and-relu)

- [Reading - Dense Layers and ReLU](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/9G7vx/dense-layers-and-relu)

- [Video - Embedding and Mean Layers](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/CT6YH/embedding-and-mean-layers)

- [Reading - Embedding and Mean Layers](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/wfa54/embedding-and-mean-layers)

- [Lab - Introduction to TensorFlow](./Labs/C3W1_TensorFlow_Tutorial.ipynb)

## Practice Assignment: Classification Using Deep Neural Networks

- [Lab - Sentiment with Deep Neural Networks](./Labs/C3W1_Practice_Assignment.ipynb)

## N-grams vs. Sequence Models

- [Video - Lesson Introduction](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/XAIyJ/lesson-introduction)

- [Video - Traditional Language models](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/adQKz/traditional-language-models)

- [Reading - Traditional Language models](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/jDg7N/traditional-language-models)

- [Video - Recurrent Neural Networks](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/SgnFd/recurrent-neural-networks)

- [Reading - Recurrent Neural Networks](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/TyJuk/recurrent-neural-networks)

- [Video - Applications of RNNs](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/VLEGc/applications-of-rnns)

- [Reading - Applications of RNNs](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/1iglC/application-of-rnns)

- [Video - Math in Simple RNNs](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/q9vfy/math-in-simple-rnns)

- [Reading - Math in Simple RNNs](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/eaLt6/math-in-simple-rnns)

- [Lab - Hidden State Activation](./Labs/C3W1_Hidden_State_Activation.ipynb)

- [Video - Cost Function for RNNs](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/v14dP/cost-function-for-rnns)

- [Reading - Cost Function for RNNs](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/KBmVE/cost-function-for-rnns)

- [Video - Implementation Note](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/402Mt/implementation-note)

- [Reading - Implementation Note](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/rhso8/implementation-note)

- [Video - Gated Recurrent Units](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/U2BcV/gated-recurrent-units)

- [Reading - Gated Recurrent Units](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/t5L3H/gated-recurrent-units)

- [Lab - Vanilla RNNs, GRUs and the scan function](./Labs/C3W1_RNNs.ipynb)

- [Video - Deep and Bi-directional RNNs](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/xHrTe/deep-and-bi-directional-rnns)

- [Reading - Deep and Bi-directional RNNs](https://www.coursera.org/learn/sequence-models-in-nlp/supplement/TBXN7/deep-and-bi-directional-rnns)

- [Reading - Calculating Perplexity](https://www.coursera.org/learn/probabilistic-models-in-nlp/lecture/SEO4T/language-model-evaluation)

- [Lab - Calculating Perplexity](./Labs/C3W1_perplexity.ipynb)

- [Video - Week Conclusion](https://www.coursera.org/learn/sequence-models-in-nlp/lecture/cfAvr/week-conclusion)

## Lecture Notes (Optional)

- [Reading - Lecture Notes W1](./Readings/C3_W1.pdf)

## Assignment: Deep N-grams

- [Lab - Deep N-grams](./Labs/C3W1_Assignment.ipynb)
