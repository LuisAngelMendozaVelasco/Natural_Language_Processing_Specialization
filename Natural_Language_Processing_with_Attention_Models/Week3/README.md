# Question Answering

Explore transfer learning with state-of-the-art models like T5 and BERT, then build a model that can answer questions.

## Learning Objectives

- Gain intuition for how transfer learning works in the context of NLP
- Identify two approaches to transfer learning
- Discuss the evolution of language models from CBOW to T5 and Bert
- Fine-tune BERT on a dataset
- Implement context-based question answering with T5
- Interpret the GLUE benchmark

## Question Answering

- [Video - Week Introduction](https://www.coursera.org/learn/attention-models-in-nlp/lecture/aoycG/week-introduction)

- [Video - Week 3 Overview](https://www.coursera.org/learn/attention-models-in-nlp/lecture/SMxuK/week-3-overview)

- [Reading - Week 3 Overview](https://www.coursera.org/learn/attention-models-in-nlp/supplement/b1XuK/week-3-overview)

- [Video - Transfer Learning in NLP](https://www.coursera.org/learn/attention-models-in-nlp/lecture/qMRXX/transfer-learning-in-nlp)

- [Reading - Transfer Learning in NLP](https://www.coursera.org/learn/attention-models-in-nlp/supplement/6q7Xl/transfer-learning-in-nlp)

- [Video - ELMo, GPT, BERT, T5](https://www.coursera.org/learn/attention-models-in-nlp/lecture/iPUp8/elmo-gpt-bert-t5)

- [Reading - ELMo, GPT, BERT, T5](https://www.coursera.org/learn/attention-models-in-nlp/supplement/2j4D3/elmo-gpt-bert-t5)

- [Video - Bidirectional Encoder Representations from Transformers (BERT)](https://www.coursera.org/learn/attention-models-in-nlp/lecture/lZX7F/bidirectional-encoder-representations-from-transformers-bert)

- [Reading - Bidirectional Encoder Representations from Transformers (BERT)](https://www.coursera.org/learn/attention-models-in-nlp/supplement/Ly0mk/bidirectional-encoder-representations-from-transformers-bert)

- [Video - BERT Objective](https://www.coursera.org/learn/attention-models-in-nlp/lecture/1g8LM/bert-objective)

- [Reading - BERT Objective](https://www.coursera.org/learn/attention-models-in-nlp/supplement/TXXrt/bert-objective)

- [Video - Fine tuning BERT](https://www.coursera.org/learn/attention-models-in-nlp/lecture/EMBvt/fine-tuning-bert)

- [Reading - Fine tuning BERT](https://www.coursera.org/learn/attention-models-in-nlp/supplement/CSZpm/fine-tuning-bert)

- [Video - Transformer: T5](https://www.coursera.org/learn/attention-models-in-nlp/lecture/dDSZk/transformer-t5)

- [Reading - Transformer: T5](https://www.coursera.org/learn/attention-models-in-nlp/supplement/5PZLm/transformer-t5)

- [Video - Multi-Task Training Strategy](https://www.coursera.org/learn/attention-models-in-nlp/lecture/vhRkb/multi-task-training-strategy)

- [Reading - Multi-Task Training Strategy](https://www.coursera.org/learn/attention-models-in-nlp/supplement/dg3wb/multi-task-training-strategy)

- [Video - GLUE Benchmark](https://www.coursera.org/learn/attention-models-in-nlp/lecture/h2IJz/glue-benchmark)

- [Reading - GLUE Benchmark](https://www.coursera.org/learn/attention-models-in-nlp/supplement/epY9s/glue-benchmark)

- [Lab - SentencePiece and BPE](./Labs/C4W3_SentencePiece_and_BPE.ipynb)

## Hugging Face

- [Reading - Welcome to Hugging Face ðŸ¤—](https://www.coursera.org/learn/attention-models-in-nlp/supplement/6DnvX/welcome-to-hugging-face-nak)

- [Video - Hugging Face Introduction](https://www.coursera.org/learn/attention-models-in-nlp/lecture/Xtxav/hugging-face-introduction)

- [Video - Hugging Face I](https://www.coursera.org/learn/attention-models-in-nlp/lecture/vFKh2/hugging-face-i)

- [Video - Hugging Face II](https://www.coursera.org/learn/attention-models-in-nlp/lecture/el1tC/hugging-face-ii)

- [Video - Hugging Face III](https://www.coursera.org/learn/attention-models-in-nlp/lecture/ssUbG/hugging-face-iii)

- [Video - Week Conclusion](https://www.coursera.org/learn/attention-models-in-nlp/lecture/FIzSZ/week-conclusion)

- [Lab - Question Answering with HuggingFace - Using a base model](./Labs/C4W3_HF_Lab1_QA_BERT.ipynb)

- [Lab - Question Answering with HuggingFace 2 - Fine-tuning a model](./Labs/C4W3_HF_Lab2_QA_BERT.ipynb)

- [Reading - Content Resource](https://www.coursera.org/learn/attention-models-in-nlp/supplement/IHbrg/links-to-the-resources)

## Lecture Notes (Optional)

- [Reading - Lecture Notes W3](./Readings/C4_W3.pdf)

## Assignment

- [Lab - Question Answering](./Labs/C4W3_Assignment.ipynb)

## Heroes of NLP: Quoc Le

- [Video - Andrew Ng with Quoc Le](https://www.coursera.org/learn/attention-models-in-nlp/lecture/oPZYO/andrew-ng-with-quoc-le)

## Acknowledgments & Course Resources

- [Reading - References](https://www.coursera.org/learn/attention-models-in-nlp/supplement/IHbrg/references)
